## Simulair: Procedural Terrain Generation for Drone Obstacle Avoidance
Training vision‐based obstacle avoidance models purely through real‐world drone flights is cost prohibitive, dangerous, and limited in environmental diversity. We introduce Simulair, a fully automated, headless simulation pipeline that transforms natural language terrain descriptions into detailed 3D terrain, procedurally scatters static obstacles (e.g. trees, rocks, mountains), and coordinates massively parallelized flight runs for end-to-end reinforcement learning (RL) training. Our pipeline utilizes Stable Diffusion 3.5 Large Turbo (SD3.5 LT) for photorealistic image synthesis, Stable Point Aware 3D (SPAR3D) for single-image mesh reconstruction, and Infinigen for ecological base environments and PBR material assignment. All assets converge into USD (Universal Scene Description) format, which feeds directly into NVIDIA IsaacSim. Within IsaacSim, a PX4 software-in-the-loop (SITL) stack in Pegasus simulator flies a depth-aware quadcopter under ORB-SLAM2 state estimation. Control policies employ an Advantage Actor-Critic (A2C) architecture, trained on collision events, depth maps, and pose estimates. Over several unique procedurally generated biomes and simulated flight hours, policies trained in Simulair demonstrate viable avoidance trajectories and SLAM tracking under clutter. We provide a comprehensive technical outline: prompt engineering heuristics, mesh fusion strategies, physics collider tradeoffs, GPU memory optimization, headless coordination, and remote compute integration. We discuss limitations such as photometric discrepancies, collider approximations, VRAM ceilings, and prompt ambiguity. Finally, we outline future directions including RTX path tracing, deformable vegetation, extended sensor modalities, and cloud deployment.
